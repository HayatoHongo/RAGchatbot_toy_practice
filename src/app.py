# src/app.py

import os
import sqlite3
from pathlib import Path
from dotenv import load_dotenv
import streamlit as st
from chromadb import PersistentClient

# --- ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ ---
load_dotenv()
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

# --- ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from data_loader import docs
from preprocess import chunk_texts
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from qa_chain import QA_PROMPT  # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

# --- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆï¼†DBãƒ‘ã‚¹ ---
ROOT    = Path(__file__).parent.parent
DB_PATH = str(ROOT / "chroma_db")

# --- RAG æ§‹ç¯‰ ---
# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒãƒ£ãƒ³ã‚¯åŒ–
chunks, metadatas = chunk_texts(docs)
# åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«
emb = OpenAIEmbeddings(model="text-embedding-ada-002")
# PersistentClient ã‚’å…±æœ‰
client      = PersistentClient(path=DB_PATH)
# Chroma retriever
vectorstore = Chroma(
    client=client,
    collection_name="internal_docs",
    embedding_function=emb
)
retriever   = vectorstore.as_retriever(search_kwargs={"k": 3})
# QA ãƒã‚§ãƒ¼ãƒ³
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True,
    chain_type_kwargs={"prompt": QA_PROMPT}
)

# --- Streamlit UIè¨­å®š ---
st.set_page_config(page_title="ç¤¾å†…æ–‡æ›¸ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ", layout="wide")
st.title("ğŸ“„ ç¤¾å†…æ–‡æ›¸ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
st.write("ç¤¾å†…è¦ç¨‹ã‚„ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«é–¢ã™ã‚‹è³ªå•ã«ãŠç­”ãˆã—ã¾ã™ã€‚")

# --- ãƒ‡ãƒãƒƒã‚°ç”¨ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
st.sidebar.header("ğŸ”§ ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰")
show_db    = st.sidebar.checkbox("ğŸ” DBãƒ‘ã‚¹ç¢ºèª")
show_ch    = st.sidebar.checkbox("ğŸ” Chroma ç›´èª­")
show_cnt   = st.sidebar.checkbox("ç™»éŒ²ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’è¡¨ç¤º")
show_hits  = st.sidebar.checkbox("Retriever ãƒ’ãƒƒãƒˆã‚’è¡¨ç¤º")
show_raw   = st.sidebar.checkbox("ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¡¨ç¤º")
show_prompt= st.sidebar.checkbox("é€ä¿¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¡¨ç¤º")

# --- DBãƒ‘ã‚¹ç¢ºèª ---
if show_db:
    st.sidebar.write("ğŸ  ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª:", os.getcwd())
    st.sidebar.write("ğŸ“ DB_PATH:", DB_PATH)
    st.sidebar.write("ğŸ“‚ DBãƒ•ã‚©ãƒ«ãƒ€å­˜åœ¨ï¼Ÿ", os.path.exists(DB_PATH))
    if os.path.exists(DB_PATH):
        st.sidebar.write("ğŸ“‚ chroma_db é…ä¸‹:", os.listdir(DB_PATH))
        try:
            dbfile = Path(DB_PATH) / "chroma.sqlite3"
            conn   = sqlite3.connect(str(dbfile))
            cur    = conn.cursor()
            cur.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [t[0] for t in cur.fetchall()]
            st.sidebar.write("ğŸ“‹ ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§:", tables)
            if "internal_docs" in tables:
                cur.execute("SELECT COUNT(*) FROM internal_docs")
                st.sidebar.write("ğŸ”¢ internal_docs ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°:", cur.fetchone()[0])
            conn.close()
        except Exception as e:
            st.sidebar.write("âŒ SQLite èª­ã¿å–ã‚Šå¤±æ•—:", e)

# --- Chroma ç›´èª­ ---
if show_ch:
    try:
        cols = [c.name for c in client.list_collections()]
        st.sidebar.write("ğŸ” ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§:", cols)
        if "internal_docs" in cols:
            col = client.get_collection(name="internal_docs")
            st.sidebar.write("ğŸ”¢ internal_docs ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°:", col.count())
    except Exception as e:
        st.sidebar.write("âŒ Chroma ç›´èª­å¤±æ•—:", e)

# --- è³ªå•å…¥åŠ›ï¼†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¡¨ç¤º ---
query = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", "")
if show_prompt and query:
    docs_for_prompt = retriever.get_relevant_documents(query)
    context = "\n\n".join([d.page_content for d in docs_for_prompt])
    prompt = QA_PROMPT.format(context=context, question=query)
    st.sidebar.subheader("ğŸ“¨ é€ä¿¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    st.sidebar.text_area("", prompt, height=300)

# --- è³ªå•ã®å®Ÿè¡Œ ---
if st.button("é€ä¿¡") and query:
    with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­â€¦"):
        res = qa_chain({"query": query})

    # å›ç­”è¡¨ç¤º
    st.subheader("ğŸ’¬ å›ç­”")
    st.write(res["result"])

    # å‚ç…§å…ƒè¡¨ç¤º
    st.subheader("ğŸ“š å‚ç…§å…ƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
    if res.get("source_documents"):
        for doc in res["source_documents"]:
            sid     = doc.metadata.get("source", "unknown")
            snippet = doc.page_content.strip().replace("\n", " ")[:100]
            st.markdown(f"- **{sid}**: {snippet}...")
    else:
        st.write("å‚ç…§å…ƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    # --- ãƒ‡ãƒãƒƒã‚°æƒ…å ± ---
    if show_cnt:
        try:
            cnt = vectorstore._collection.count()
        except:
            cnt = "å–å¾—å¤±æ•—"
        st.sidebar.write(f"ç™»éŒ²ãƒãƒ£ãƒ³ã‚¯æ•°ï¼š{cnt}")

    if show_hits:
        st.sidebar.subheader("Retriever.get_relevant_documents() çµæœ")
        hits = retriever.get_relevant_documents(query)
        if hits:
            for i, d in enumerate(hits, 1):
                sid  = d.metadata.get("source", "unknown")
                text = d.page_content.strip().replace("\n", " ")[:80]
                st.sidebar.write(f"{i}. [{sid}] {text}...")
        else:
            st.sidebar.write("ãƒ’ãƒƒãƒˆãªã—")

    if show_raw:
        st.sidebar.subheader("ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ JSON")
        st.sidebar.json(res)
